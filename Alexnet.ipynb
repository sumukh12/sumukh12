{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Alexnet",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXgIV5opUazI",
        "outputId": "29b59d99-0193-45d5-a650-c93f42f8b100"
      },
      "source": [
        "!pip install tflearn"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tflearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/3c/0b156d08ef3d4e2a8009ecab2af1ad2e304f6fb99562b6271c68a74a4397/tflearn-0.5.0.tar.gz (107kB)\n",
            "\r\u001b[K     |███                             | 10kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 20kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 30kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 40kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 61kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 71kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 81kB 6.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 92kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 102kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tflearn) (7.1.2)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.5.0-cp37-none-any.whl size=127300 sha256=dbdfb1ca3a17e5a1a886e200ce56c9f3b11bf6da9c532c0ca0809af486640025\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/d2/ed/fb9a0d301dd9586c11e9547120278e624227f22fd5f4baf744\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgfaGnfiKTfq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e4b10564-a284-450a-aa6c-34ef8fe572b5"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation,Dropout,Flatten,Conv2D,MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "np.random.seed(1000)\n",
        "\n",
        "\n",
        "\n",
        "#3create a sequential model\n",
        "model=Sequential()\n",
        "#1st convolutional layer\n",
        "model.add(Conv2D(filters=96,input_shape=(224,224,3),kernel_size=(11,11),strides=(4,4),padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "#pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'))\n",
        "#Batch normalization before passing to next layer\n",
        "model.add(BatchNormalization())\n",
        "#2nd convolutional layer\n",
        "model.add(Conv2D(filters=256,kernel_size=(11,11),strides=(1,1),padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "#pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'))\n",
        "#Batch Normalization\n",
        "model.add(BatchNormalization())\n",
        "#3rd convutional layer\n",
        "model.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "#4th convolutional layer\n",
        "model.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "#5TH convolutional layer\n",
        "model.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#passing to dense layer\n",
        "model.add(Flatten())\n",
        "#1st dense layer\n",
        "model.add(Dense(4096,input_shape=(224*224*3,)))\n",
        "model.add(Activation('relu'))\n",
        "#Add dropout to prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "#Batch normalization\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#2nd Dense layer\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "#add dropout\n",
        "model.add(Dropout(0.4))\n",
        "#Batch Normalization\n",
        "model.add(BatchNormalization())\n",
        "#3rd dense layer\n",
        "model.add(Dense(1000))\n",
        "model.add(Activation('relu'))\n",
        "#add dropout\n",
        "model.add(Dropout(0.4))\n",
        "#Batch Normalization\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#output layer\n",
        "model.add(Dense(17))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#(4)compile\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "#5 train\n",
        "model.fit(x,y,batch_size=60,epochs=1,verbose=1,validation_split=0.2,shuffle=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_32 (Conv2D)           (None, 54, 54, 96)        34944     \n",
            "_________________________________________________________________\n",
            "activation_44 (Activation)   (None, 54, 54, 96)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 27, 27, 96)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_40 (Batc (None, 27, 27, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 17, 17, 256)       2973952   \n",
            "_________________________________________________________________\n",
            "activation_45 (Activation)   (None, 17, 17, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_41 (Batc (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 6, 6, 384)         885120    \n",
            "_________________________________________________________________\n",
            "activation_46 (Activation)   (None, 6, 6, 384)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_42 (Batc (None, 6, 6, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 4, 4, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "activation_47 (Activation)   (None, 4, 4, 384)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_43 (Batc (None, 4, 4, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 2, 2, 256)         884992    \n",
            "_________________________________________________________________\n",
            "activation_48 (Activation)   (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_44 (Batc (None, 2, 2, 256)         1024      \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 4096)              4198400   \n",
            "_________________________________________________________________\n",
            "activation_49 (Activation)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_45 (Batc (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "activation_50 (Activation)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_46 (Batc (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "activation_51 (Activation)   (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_47 (Batc (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 17)                17017     \n",
            "_________________________________________________________________\n",
            "activation_52 (Activation)   (None, 17)                0         \n",
            "=================================================================\n",
            "Total params: 31,242,497\n",
            "Trainable params: 31,221,361\n",
            "Non-trainable params: 21,136\n",
            "_________________________________________________________________\n",
            "Train on 1088 samples, validate on 272 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FailedPreconditionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-dcfa61a660ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m#5 train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4019\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 4020\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   4021\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4022\u001b[0m     output_structure = tf.nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1480\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1481\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m: Could not find variable training_6/Adam/iter. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status=Not found: Resource localhost/training_6/Adam/iter/N10tensorflow3VarE does not exist.\n\t [[{{node training_6/Adam/ReadVariableOp}}]]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA2n4kx63LdN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}